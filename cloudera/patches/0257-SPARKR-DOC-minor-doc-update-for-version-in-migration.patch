From e453e051ff68d60a3487b60f34370623ab85acbf Mon Sep 17 00:00:00 2001
From: felixcheung <felixcheung_m@hotmail.com>
Date: Tue, 5 Jan 2016 08:39:58 +0530
Subject: [PATCH 257/517] [SPARKR][DOC] minor doc update for version in
 migration guide

checked that the change is in Spark 1.6.0.
shivaram

Author: felixcheung <felixcheung_m@hotmail.com>

Closes #10574 from felixcheung/rwritemodedoc.

(cherry picked from commit 8896ec9f02a6747917f3ae42a517ff0e3742eaf6)
Signed-off-by: Shivaram Venkataraman <shivaram@cs.berkeley.edu>
(cherry picked from commit 8950482ee5e9132d11dc5b5d41132bb1fe1e7ba2)
---
 docs/sparkr.md |    6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/docs/sparkr.md b/docs/sparkr.md
index 9ddd2ed..ea81532 100644
--- a/docs/sparkr.md
+++ b/docs/sparkr.md
@@ -385,12 +385,12 @@ The following functions are masked by the SparkR package:
 </table>
 
 Since part of SparkR is modeled on the `dplyr` package, certain functions in SparkR share the same names with those in `dplyr`. Depending on the load order of the two packages, some functions from the package loaded first are masked by those in the package loaded after. In such case, prefix such calls with the package name, for instance, `SparkR::cume_dist(x)` or `dplyr::cume_dist(x)`.
-  
+
 You can inspect the search path in R with [`search()`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/search.html)
 
 
 # Migration Guide
 
-## Upgrading From SparkR 1.6 to 1.7
+## Upgrading From SparkR 1.5.x to 1.6
 
- - Until Spark 1.6, the default mode for writes was `append`. It was changed in Spark 1.7 to `error` to match the Scala API.
+ - Before Spark 1.6, the default mode for writes was `append`. It was changed in Spark 1.6.0 to `error` to match the Scala API.
-- 
1.7.9.5

