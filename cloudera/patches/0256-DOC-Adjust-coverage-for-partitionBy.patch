From 320886e3b8f9424a6a622ba5089b69676ea9c8aa Mon Sep 17 00:00:00 2001
From: tedyu <yuzhihong@gmail.com>
Date: Mon, 4 Jan 2016 12:38:04 -0800
Subject: [PATCH 256/517] [DOC] Adjust coverage for partitionBy()

This is the related thread: http://search-hadoop.com/m/q3RTtO3ReeJ1iF02&subj=Re+partitioning+json+data+in+spark

Michael suggested fixing the doc.

Please review.

Author: tedyu <yuzhihong@gmail.com>

Closes #10499 from ted-yu/master.

(cherry picked from commit 40d03960d79debdff5cef21997417c4f8a8ce2e9)
Signed-off-by: Michael Armbrust <michael@databricks.com>
(cherry picked from commit 1005ee396f74dc4fcf127613b65e1abdb7f1934c)
---
 .../org/apache/spark/sql/DataFrameWriter.scala     |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/sql/core/src/main/scala/org/apache/spark/sql/DataFrameWriter.scala b/sql/core/src/main/scala/org/apache/spark/sql/DataFrameWriter.scala
index 9f59c0f..9afa685 100644
--- a/sql/core/src/main/scala/org/apache/spark/sql/DataFrameWriter.scala
+++ b/sql/core/src/main/scala/org/apache/spark/sql/DataFrameWriter.scala
@@ -119,7 +119,7 @@ final class DataFrameWriter private[sql](df: DataFrame) {
    * Partitions the output by the given columns on the file system. If specified, the output is
    * laid out on the file system similar to Hive's partitioning scheme.
    *
-   * This is only applicable for Parquet at the moment.
+   * This was initially applicable for Parquet but in 1.5+ covers JSON, text, ORC and avro as well.
    *
    * @since 1.4.0
    */
-- 
1.7.9.5

